{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt \n",
    "\n",
    "# file locations\n",
    "BASEPATH = {\n",
    "    'darwin': '/Users/patrick/Dropbox/datascienceud/vis/raw',\n",
    "    'linux': '/home/patrick/Dropbox/datascienceud/vis/raw',\n",
    "}\n",
    "basepath = BASEPATH.get(sys.platform)\n",
    "\n",
    "csvfilename = os.path.join(basepath, 'fligth_delay_cause_monthly_2003_2017.csv')\n",
    "airportscsv = os.path.join(basepath, 'master_airports.csv')\n",
    "\n",
    "# read raw data\n",
    "delays = pd.read_csv(csvfilename)\n",
    "delays.columns = [col.strip() for col in delays.columns]\n",
    "\n",
    "airports = pd.read_csv(airportscsv)\n",
    "airports.columns = [c.lower() for c in airports.columns]\n",
    "\n",
    "# utilities\n",
    "c = lambda v: v.split(',')\n",
    "\n",
    "# get unique data\n",
    "airports = airports.drop_duplicates(c('airport'))\n",
    "assert len(airports.groupby('airport').filter(lambda v: len(v) > 1)) == 0, \"there are duplicates\"\n",
    "airports.columns\n",
    "\n",
    "# merge delays and airport fips\n",
    "delays = delays.merge(airports[c('airport,airport_state_code,airport_state_fips')], on=c('airport'), how='left')\n",
    "delays['arr_del15_pct'] = delays.arr_del15 / delays.arr_flights\n",
    "delays.rename(columns=dict(airport_state_fips='fips',\n",
    "                           airport_state_code='state'), inplace=True)\n",
    "delays['fips'] = delays.fips.dropna().apply(lambda v: 'US{:02d}'.format(int(v)))\n",
    "\n",
    "# calculate percentage of flights per cause\n",
    "for ctcol in [col for col in delays.columns if col.endswith('_ct')]:\n",
    "    delays['{}_pct'.format(ctcol)] = delays[ctcol] / delays['arr_del15']\n",
    "    \n",
    "# average delay\n",
    "delays['arr_del15_avg'] = delays.arr_delay / delays.arr_flights\n",
    "\n",
    "# prepare delays by cause csv\n",
    "groupcol = ['year']\n",
    "ctpctcols = [col for col in delays.columns if col.endswith('_ct_pct')]\n",
    "dfx = delays[groupcol + ctpctcols].groupby(groupcol).median()\n",
    "dfx.plot(by=groupcol)\n",
    "dfx.reset_index().to_csv('data/delays_cause_year.csv')\n",
    "dfx = dfx.reset_index()\n",
    "dfx = dfx.melt(id_vars=['year'], var_name='name')\n",
    "dfx.to_csv('data/delays_cause_year.csv')\n",
    "\n",
    "# prepare by airport csv\n",
    "cols = c('year,month,carrier,carrier_name,airport_name,fips,state,arr_flights,arr_del15,carrier_ct,weather_ct,nas_ct')\n",
    "dfx = delays[cols]\n",
    "dfx = dfx.groupby(c('year,state,fips')).sum().reset_index()\n",
    "dfx = dfx.groupby(c('state,fips')).mean().reset_index()\n",
    "dfx.to_csv('data/airport_causes.csv', float_format='%.3f', quoting=csv.QUOTE_NONNUMERIC)\n",
    "dfx.sort_values('arr_del15', ascending=False)\n",
    "\n",
    "# cause by carrier\n",
    "for v in ['arr_del15', 'carrier_ct_pct', 'nas_ct_pct', 'late_aircraft_ct_pct']:\n",
    "    plt.figure()\n",
    "    plt.suptitle(v)\n",
    "    total = delays[v].sum()\n",
    "    causeby = delays.groupby(['carrier']).agg({v: lambda v: v.sum() / total})\n",
    "    #causeby = causeby.nlargest(10, v)\n",
    "    causeby = causeby[v].sort_values()\n",
    "    causeby.plot.bar()\n",
    "    break\n",
    "dfx = causeby.reset_index().sort_values('arr_del15').to_csv('data/causeby_carrier.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
